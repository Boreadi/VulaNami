# -*- coding: utf-8 -*-
"""vula-nami-test2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qxj8fnz5tc5InURCeBfhX_yJv7rvCZXH
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# # !pip install retry_requests
# # !pip install -U vulavula  -q
# # !pip install noisereduce
# # !pip install librosa
# # !pip install transformers
# # !pip install qfrency

from retry_requests import retry
from requests import Session

from vulavula import VulavulaClient
from vulavula.common.error_handler import VulavulaError

api_key = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6IjcwNjAyM2NkNmQyMzQzOGRiOWU4ZWQwMjYyMGFjOTM5IiwiY2xpZW50X2lkIjozMSwicmVxdWVzdHNfcGVyX21pbnV0ZSI6MCwibGFzdF9yZXF1ZXN0X3RpbWUiOm51bGx9.T9tbypdARqIXLRI6a2kRrNpfwnmg-lc0D-Hj0rh0q5g'

VULAVULA_TOKEN = api_key
# Our headers for authentication
headers={
    "X-CLIENT-TOKEN": VULAVULA_TOKEN,
}

# The transport API to upload your file
TRANSPORT_URL = "https://vulavula-services.lelapa.ai/api/v1/transport/file-upload"

# The transcribe API URL to kick off your transcription job.
TRANSCRIBE_URL = "https://vulavula-services.lelapa.ai/api/v1/transcribe/process/"

# When transcription is complete, our system calls a webhook that you provide.
# Here, we’re using a demo webhook from webhook.site for testing.
# WEBHOOK_URL="https://webhook.site/793085d1-aedb-4aba-9151-a931a7efba54"
WEBHOOK_URL="https://webhook.site/637a5a5f-c8a1-4869-87d5-85431d23fdc9"

# Name of the file you are transcribing
FILE_TO_TRANSCRIBE = "/content/common_voice_zu_39879093.mp3"

client = VulavulaClient(VULAVULA_TOKEN)



import time

## Transcribe isiZulu speech to text
def transcribe_speech(audio_file):
  try:
      upload_id, transcription_result = client.transcribe(audio_file, webhook=WEBHOOK_URL)
      print("Acknowledgement:", transcription_result) #A success message, data is sent to webhook
  except VulavulaError as e:
      print("An error occurred:", e.message)
      if 'details' in e.error_data:
          print("Error Details:", e.error_data['details'])
      else:
          print("No additional error details are available.")
  except Exception as e:
      print("An unexpected error occurred:", str(e))

  while client.get_transcribed_text(upload_id)['message'] == "Item has not been processed.":
      time.sleep(5)
      print("Waiting for transcribe to complete...")
  transcribed = client.get_transcribed_text(upload_id)
  # print(transcribed)
  tr = transcribed.get('text')

  return tr, print(f'transcribed text: {tr}')

# tr = transcribe_speech(FILE_TO_TRANSCRIBE)
to_trns = """Ukusho lokhu kulandela izincwadi ezilokhu ziputshuke njalo ze-DA iveza izikhundla ezifunayo kuhulumeni. Encwadini kaRamaposa yangoLwesibili, utshele uSteenhuisen ukuthi uyaqhubeka nezingxoxo zokubumba lo hulumeni namanye amaqembu asayine isivumelwano sokusebenzisana. Uthe udaba lokubumba uhulumeni luseqhulwini njengoba efuna ukuluphothula kuleli sonto. “Ngizimisele ukuphothula izingxoxo nokubonisana ngeyokwakha lo hulumeni kuleli sonto. Ngisavulelekile ukuthi ngibe nengxoxo nawe,” kusho uRamaphosa kuSteenhuisen. Ngale mpelasonto i-ANC izohlangana nezinhlaka zayo okubalwa namadlelandawonye ukuzozazisa ngebanga eselihanjiwe kulezi zingxoxo. Ngemuva kwale mihlangano kulindeleke ukuthi amemezele iKhabhinethi entsha njengoba abantu bakuleli belinde ngabomvu lesi simemezelo."""

## Translate IsiZulu Text to English
def translate_zul_text(zul_txt):
  translation_data = {
    # "input_text": "Iyiphi ingxenye yomzimba oyisebenzisa uma uhamba?",
    "input_text": f"{zul_txt}",
    "source_lang": "zul_Latn",
    "target_lang": "eng_Latn"
  }

  translation_result = client.translate(translation_data)
  print("Translation Result:", translation_result)
  trns = translation_result.get('translation')
  trns = trns[0].get('translation_text')
  # cleaned_translation_text = trns.strip("()").split(",")[0].strip("' ")
  return trns #cleaned_translation_text

# trns = translate_zul_text(tr)
news_trns = translate_zul_text(to_trns)

print(news_trns)

## Test
import IPython
import IPython.display as ipd

# directions = '/content/directions-sima-1.mp4'
# news = '/content/sports-llm-sibo.mp3'
news = 'C:\Users\Esther\OneDrive\Documents\vulanami\VulaNami\output.wav'
IPython.display.Audio(news)

## Test on Sima's voice sample

tr = transcribe_speech(news)
trns = translate_zul_text(tr)

"""LLM Testinng"""

trns

import pandas as pd
from transformers import T5Tokenizer, T5ForConditionalGeneration
import requests
from bs4 import BeautifulSoup

# Load the CSV archive
file_path = '/content/isizulu-titles-all-categories.csv'
data = pd.read_csv(file_path)

# fetch_article_date(sports_articles['url'])

response = requests.get(latest_article['url'])
soup = BeautifulSoup(response.content, 'html.parser')
article_content = soup.find('div', class_='article-content').text  # Adjust based on the actual HTML structure

return latest_article['title'], article_content

def t5_summarize(text):
    # Load pre-trained T5 model and tokenizer
    model_name = 't5-base'
    tokenizer = T5Tokenizer.from_pretrained(model_name)
    model = T5ForConditionalGeneration.from_pretrained(model_name)

    # Tokenize the input text
    inputs = tokenizer.encode("summarize: " + text, return_tensors="pt", max_length=1024, truncation=True)

    # Generate the summary
    summary_ids = model.generate(inputs, max_length=150, num_beams=4, early_stopping=True)

    # Decode and return the summary
    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
    return summary

# Define or import your transcribe_speech_to_text, translate_text, and text_to_speech functions

summary = t5_summarize(trns)

print("Summary:", summary)

summary = t5_summarize(news_trns)

print(summary)

## Translate IsiZulu Text to English
def translate_eng_text(eng_txt):
  translation_data = {
    # "input_text": "Iyiphi ingxenye yomzimba oyisebenzisa uma uhamba?",
    "input_text": f"{eng_txt}",
    "source_lang": "eng_Latn",
    "target_lang": "zul_Latn"
  }

  translation_result = client.translate(translation_data)
  print("Translation Result:", translation_result)
  trns = translation_result.get('translation')
  trns = trns[0].get('translation_text')
  # cleaned_translation_text = trns.strip("()").split(",")[0].strip("' ")
  return trns #cleaned_translation_text

zul_sum = translate_eng_text(summary)

print(zul_sum)

import qfrency

def write_wav_to_file(wav, filename):
    p = open(filename, "wb")
    p.write(wav)
    p.close()

# instansiate a cloud API instance

# Lelapa Hackathon Account Key
X_ACCOUNT_KEY = "0b5091da-7a2b-476c-9b6d-517baa078ee8" # share this with Hackathon participants

# Lelapa Hackathon API Keys
X_API_KEY = "263a08cc-4a1e-4f3c-aef9-69b1223fe668" # share this with Hackathon participants

cloud_api = qfrency.QfrencyCloudTTS(X_ACCOUNT_KEY, X_API_KEY)

print("available voices = {}".format(cloud_api.voices))

# but you can ask the engine to downsample
print("synthesizing sample 3")
synthed_wav_3 = cloud_api.synth("zul-ZA-dnn-lindiwe", zul_sum,
                                {"sample-rate" :16000})
write_wav_to_file(synthed_wav_3, "sum_zul_newsample.wav")

a = '/content/sum_zul_newsample.wav'
IPython.display.Audio(a)

